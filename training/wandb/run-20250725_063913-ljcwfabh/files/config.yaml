_wandb:
    value:
        cli_version: 0.21.0
        e:
            zr0ub6a077dik8xs2sc9qir73mhezmns:
                args:
                    - --node-ip-address=240.25.216.128
                    - --node-manager-port=41315
                    - --object-store-name=/mnt/tmp/ray/session_2025-07-25_06-38-51_371967_2297834/sockets/plasma_store
                    - --raylet-name=/mnt/tmp/ray/session_2025-07-25_06-38-51_371967_2297834/sockets/raylet
                    - --redis-address=None
                    - --metrics-agent-port=56045
                    - --logging-rotate-bytes=536870912
                    - --logging-rotate-backup-count=5
                    - --runtime-env-agent-port=53017
                    - --gcs-address=240.25.216.128:45774
                    - --session-name=session_2025-07-25_06-38-51_371967_2297834
                    - --temp-dir=/mnt/tmp/ray
                    - --webui=127.0.0.1:8265
                    - --cluster-id=e6177dd00a622a23ef68541fe2a97423ee2949ea77a960db2dc68e47
                    - --startup-token=96
                    - --worker-launch-time-ms=1753425536200
                    - --node-id=a1cfa3b9b1caaa9927857f82f94db03998cc35cb3e901f4c6fd0f24f
                    - --runtime-env-hash=1417985805
                    - --enable-resource-isolation=false
                cpu_count: 48
                cpu_count_logical: 96
                cudaVersion: "12.2"
                disk:
                    /:
                        total: "523982073856"
                        used: "376337989632"
                email: mert_cemri@berkeley.edu
                executable: /root/miniconda3/envs/ctu/bin/python
                git:
                    commit: aa874cb085ba185dc7ca0597d137142de6acf2d0
                    remote: https://github.com/mert-cemri/CTU-Agent-v0.git
                gpu: NVIDIA A100-SXM4-80GB
                gpu_count: 8
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-a9da7cf3-bbaa-ac1c-b8d8-658e18b82899
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-2f1c7261-31d3-c735-a6dc-e87f070a2c24
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-68959385-7689-cea6-b46b-a74a2dba5996
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-6fb2930b-6de9-a2e0-dc19-502e7c08568b
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-966bea1d-092e-035e-c3e2-085f63f1d1ea
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-5d770c41-5c95-442e-1735-28a87d1d23c0
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-47cc9e96-c38d-7df7-bcac-c3ed0ee3817c
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-bf6935fa-8e80-8dd3-44ed-f027df36876d
                host: bolt-tknhasm8xd-vwu4ng9ezs
                memory:
                    total: "1437332611072"
                os: Linux-6.6.72+-x86_64-with-glibc2.35
                program: /root/miniconda3/envs/ctu/lib/python3.12/site-packages/ray/_private/workers/default_worker.py
                python: CPython 3.12.11
                root: /root/CTU-Agent-v0/training
                startedAt: "2025-07-25T06:39:13.206283Z"
                writerId: zr0ub6a077dik8xs2sc9qir73mhezmns
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 53
                - 71
                - 98
                - 105
            "2":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 53
                - 71
                - 98
                - 105
            "3":
                - 2
                - 13
                - 16
            "4": 3.12.11
            "5": 0.21.0
            "6": 4.53.2
            "12": 0.21.0
            "13": linux-x86_64
data:
    value:
        train_data:
            - data/tau_bench_retail/train.parquet
        val_data:
            - data/tau_bench_retail/validation.parquet
deepspeed_config:
    value:
        eval:
            gradient_clipping: 1
            prescale_gradient: false
            wall_clock_breakdown: false
            zero_optimization:
                offload_param:
                    device: cpu
                    pin_memory: true
                stage: 3
                stage3_param_persistence_threshold: auto
        train:
            data_types:
                grad_accum_dtype: fp32
            disable_trace_cache: false
            gradient_clipping: 1
            prescale_gradient: false
            wall_clock_breakdown: false
            zero_optimization:
                offload_optimizer:
                    device: none
                    pin_memory: true
                offload_param:
                    device: none
                reduce_bucket_size: auto
                round_robin_gradients: true
                stage: 3
                stage3_max_live_parameters: auto
                stage3_max_reuse_distance: auto
                stage3_param_persistence_threshold: auto
                stage3_prefetch_bucket_size: auto
                sub_group_size: auto
                zero_hpz_partition_size: 1
                zero_quantized_gradients: false
                zero_quantized_weights: false
environment:
    value:
        env_class: tau_bench
        skyrl_gym:
            max_env_workers: 16
            tau_bench:
                cache_environments: true
                log_conversations: true
                log_tool_calls: true
                max_turns: 6
                parallel_user_sim: false
                timeout: 120
                use_native_tool_calling: true
                user_model: gpt-4o
                user_provider: openai
                user_strategy: llm
generator:
    value:
        async_engine: true
        backend: vllm
        batched: false
        enable_chunked_prefill: true
        enable_prefix_caching: true
        enforce_eager: true
        eval_n_samples_per_prompt: 1
        eval_sampling_params:
            max_generate_length: 1024
            min_p: 0
            temperature: 0
            top_k: -1
            top_p: 1
        gpu_memory_utilization: 0.7
        inference_engine_tensor_parallel_size: 4
        max_input_length: 8192
        max_num_batched_tokens: 8192
        max_num_seqs: 256
        max_turns: 20
        model_dtype: bfloat16
        n_samples_per_prompt: 1
        num_inference_engines: 2
        override_existing_update_group: force_new
        remote_inference_engine_urls:
            - 127.0.0.1:8001
        run_engines_locally: true
        sampling_params:
            max_generate_length: 1024
            min_p: 0
            temperature: 0.7
            top_k: -1
            top_p: 0.9
        use_conversation_multi_turn: true
        use_native_tool_calling: true
        vllm_v1_disable_multiproc: true
        weight_sync_backend: nccl
        zero_reward_on_non_stop: true
trainer:
    value:
        algorithm:
            advantage_batch_normalize: false
            advantage_estimator: grpo
            clip_ratio_c: 3
            eps_clip_high: 0.2
            eps_clip_low: 0.2
            gamma: 1
            init_kl_coef: 0
            kl_loss_coef: 0.001
            kl_target: null
            lambd: 1
            loss_reduction: token_mean
            normalize_reward: true
            ppo_loss_type: regular
            use_abs_kl: false
            use_kl_estimator_k3: true
            use_kl_in_reward: false
            use_kl_loss: true
            value_clip: 0.2
            value_head_prefix: value_head
        bf16: true
        ckpt_interval: 10
        ckpt_path: /root/ckpts/tau_bench/Qwen_Qwen2.5-3B-Instruct
        critic:
            deepspeed_config:
                data_types:
                    grad_accum_dtype: fp32
                disable_trace_cache: false
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_optimizer:
                        device: none
                        pin_memory: true
                    offload_param:
                        device: none
                    reduce_bucket_size: auto
                    round_robin_gradients: true
                    stage: 3
                    stage3_max_live_parameters: auto
                    stage3_max_reuse_distance: auto
                    stage3_param_persistence_threshold: auto
                    stage3_prefetch_bucket_size: auto
                    sub_group_size: auto
                    zero_hpz_partition_size: 1
                    zero_quantized_gradients: false
                    zero_quantized_weights: false
            fsdp_config:
                cpu_offload: false
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: null
            optimizer_config:
                adam_betas:
                    - 0.9
                    - 0.999
                lr: 5e-06
                max_grad_norm: 1
                num_warmup_steps: 0
                offload_after_step: true
                weight_decay: 0.01
            sequence_parallel_size: 1
        critic_mini_batch_size: 64
        disable_fast_tokenizer: false
        dump_data_batch: false
        dump_eval_results: true
        epochs: 5
        eval_batch_size: 64
        eval_before_train: true
        eval_interval: 5
        export_path: /root/exports/tau_bench
        flash_attn: false
        gradient_checkpointing: true
        gradient_checkpointing_use_reentrant: false
        hf_save_interval: 20
        logger: wandb
        max_ckpts_to_keep: 3
        max_prompt_length: 8192
        micro_forward_batch_size_per_gpu: 1
        micro_train_batch_size_per_gpu: 1
        placement:
            colocate_all: true
            colocate_critic_reward: false
            colocate_policy_ref: true
            critic_num_gpus_per_node: 8
            critic_num_nodes: 1
            policy_num_gpus_per_node: 8
            policy_num_nodes: 1
            ref_num_gpus_per_node: 8
            ref_num_nodes: 1
            reward_num_gpus_per_node: 8
            reward_num_nodes: 1
        policy:
            deepspeed_config:
                data_types:
                    grad_accum_dtype: fp32
                disable_trace_cache: false
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_optimizer:
                        device: none
                        pin_memory: true
                    offload_param:
                        device: none
                    reduce_bucket_size: auto
                    round_robin_gradients: true
                    stage: 3
                    stage3_max_live_parameters: auto
                    stage3_max_reuse_distance: auto
                    stage3_param_persistence_threshold: auto
                    stage3_prefetch_bucket_size: auto
                    sub_group_size: auto
                    zero_hpz_partition_size: 1
                    zero_quantized_gradients: false
                    zero_quantized_weights: false
            fsdp_config:
                cpu_offload: false
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: Qwen/Qwen2.5-3B-Instruct
            optimizer_config:
                adam_betas:
                    - 0.9
                    - 0.999
                lr: 1e-06
                max_grad_norm: 1
                num_warmup_steps: 0
                offload_after_step: true
                weight_decay: 0.01
            record_memory: false
            sequence_parallel_size: 1
            use_torch_compile: false
        policy_mini_batch_size: 16
        project_name: tau_bench_rl
        ref:
            deepspeed_config:
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_param:
                        device: cpu
                        pin_memory: true
                    stage: 3
                    stage3_param_persistence_threshold: auto
            fsdp_config:
                cpu_offload: true
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: Qwen/Qwen2.5-3B-Instruct
            sequence_parallel_size: 1
        resume_mode: latest
        resume_path: null
        reward:
            deepspeed_config:
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_param:
                        device: cpu
                        pin_memory: true
                    stage: 3
                    stage3_param_persistence_threshold: auto
            fsdp_config:
                cpu_offload: true
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: null
            sequence_parallel_size: 1
        run_name: tau_bench_qwen2_5_3b_20250725_063842
        seed: 42
        sequence_parallel_backend: ulysses
        strategy: fsdp2
        target_modules: all-linear
        train_batch_size: 64
        update_epochs_per_batch: 1
        update_ref_every_epoch: false
        use_orm_score: false
        use_sample_packing: true
