_wandb:
    value:
        cli_version: 0.21.0
        e:
            czjy3nbeysylapnntx9rgnk7tt11j1bm:
                args:
                    - --node-ip-address=240.20.60.106
                    - --node-manager-port=35833
                    - --object-store-name=/mnt/tmp/ray/session_2025-08-07_06-49-21_115646_2067778/sockets/plasma_store
                    - --raylet-name=/mnt/tmp/ray/session_2025-08-07_06-49-21_115646_2067778/sockets/raylet
                    - --redis-address=None
                    - --metrics-agent-port=52215
                    - --logging-rotate-bytes=536870912
                    - --logging-rotate-backup-count=5
                    - --runtime-env-agent-port=55364
                    - --gcs-address=240.20.60.106:61123
                    - --session-name=session_2025-08-07_06-49-21_115646_2067778
                    - --temp-dir=/mnt/tmp/ray
                    - --webui=
                    - --cluster-id=4345aa7e7f8703d3471803d1a5bd8dddac071701ded1e8d6ea03918c
                    - --startup-token=96
                    - --worker-launch-time-ms=1754549364465
                    - --node-id=15e5deb3eb705a944dc73f4b313183c87f96ba513d45c0511c4cf49d
                    - --runtime-env-hash=1417985805
                    - --enable-resource-isolation=false
                cpu_count: 48
                cpu_count_logical: 96
                cudaVersion: "12.2"
                disk:
                    /:
                        total: "523982073856"
                        used: "335478636544"
                email: mert_cemri@berkeley.edu
                executable: /root/miniconda3/envs/ctu/bin/python
                git:
                    commit: 19af114ef83ceb57f39f5d200a4a9a4e0bed0687
                    remote: https://github.com/mert-cemri/CTU-Agent-v0.git
                gpu: NVIDIA A100-SXM4-80GB
                gpu_count: 8
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-e98a17de-35a5-0036-35a2-105b2629d878
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-ae823f9e-8d2e-9ee1-a389-79e73514c3b5
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-1ec64663-22ae-43f7-ac1f-768db73d365c
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-d47cee3c-9f97-8a95-49bf-1b74c17fafc0
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-ab3eb3d6-a831-a67e-8877-18efeef64afb
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-0336db73-2875-5efe-762d-04c5a18c1161
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-bb0db975-18e5-0a72-3947-1db98426142d
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-cefd4912-eba2-2bdc-d1e0-6a90cca790c5
                host: bolt-udx594w68d-ng3r4y5r7c
                memory:
                    total: "1437332611072"
                os: Linux-6.6.72+-x86_64-with-glibc2.35
                program: /root/miniconda3/envs/ctu/lib/python3.12/site-packages/ray/_private/workers/default_worker.py
                python: CPython 3.12.11
                root: /root/CTU-Agent-v0/training
                startedAt: "2025-08-07T06:49:52.146443Z"
                writerId: czjy3nbeysylapnntx9rgnk7tt11j1bm
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 71
                - 98
                - 105
            "2":
                - 1
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 71
                - 95
                - 98
                - 105
            "3":
                - 2
                - 13
                - 16
                - 61
            "4": 3.12.11
            "5": 0.21.0
            "6": 4.54.0
            "12": 0.21.0
            "13": linux-x86_64
data:
    value:
        retail_val_data:
            - data/tau_bench_retail/validation.parquet
        test_data:
            airline: data/tau_bench_test/airline_test.parquet
            retail: data/tau_bench_test/retail_test.parquet
        train_data:
            - data/tau_bench_multi/train.parquet
        val_data:
            - data/tau_bench_multi/validation.parquet
deepspeed_config:
    value:
        eval:
            gradient_clipping: 1
            prescale_gradient: false
            wall_clock_breakdown: false
            zero_optimization:
                offload_param:
                    device: cpu
                    pin_memory: true
                stage: 3
                stage3_param_persistence_threshold: auto
        train:
            data_types:
                grad_accum_dtype: fp32
            disable_trace_cache: false
            gradient_clipping: 1
            prescale_gradient: false
            wall_clock_breakdown: false
            zero_optimization:
                offload_optimizer:
                    device: none
                    pin_memory: true
                offload_param:
                    device: none
                reduce_bucket_size: auto
                round_robin_gradients: true
                stage: 3
                stage3_max_live_parameters: auto
                stage3_max_reuse_distance: auto
                stage3_param_persistence_threshold: auto
                stage3_prefetch_bucket_size: auto
                sub_group_size: auto
                zero_hpz_partition_size: 1
                zero_quantized_gradients: false
                zero_quantized_weights: false
environment:
    value:
        env_class: tau_bench
        skyrl_gym:
            max_env_workers: 16
            tau_bench:
                cache_environments: true
                log_conversations: true
                log_tool_calls: true
                max_turns: 10
                parallel_user_sim: false
                timeout: 120
                use_native_tool_calling: true
                user_model: gpt-4o
                user_provider: openai
                user_strategy: llm
generator:
    value:
        async_engine: true
        backend: vllm
        batched: false
        enable_chunked_prefill: true
        enable_prefix_caching: true
        enforce_eager: true
        eval_n_samples_per_prompt: 1
        eval_sampling_params:
            max_generate_length: 1024
            min_p: 0
            temperature: 0
            top_k: -1
            top_p: 1
        gpu_memory_utilization: 0.8
        inference_engine_tensor_parallel_size: 4
        max_input_length: 16384
        max_num_batched_tokens: 24576
        max_num_seqs: 256
        max_turns: 20
        model_dtype: bfloat16
        n_samples_per_prompt: 5
        num_inference_engines: 2
        override_existing_update_group: force_new
        remote_inference_engine_urls:
            - 127.0.0.1:8001
        run_engines_locally: true
        sampling_params:
            max_generate_length: 1024
            min_p: 0
            temperature: 0.9
            top_k: -1
            top_p: 0.9
        use_conversation_multi_turn: true
        use_native_tool_calling: true
        vllm_v1_disable_multiproc: true
        weight_sync_backend: nccl
        zero_reward_on_non_stop: true
trainer:
    value:
        algorithm:
            advantage_batch_normalize: false
            advantage_estimator: grpo
            clip_ratio_c: 3
            eps_clip_high: 0.1
            eps_clip_low: 0.1
            gamma: 1
            init_kl_coef: 0
            kl_loss_coef: 0.02
            kl_target: null
            lambd: 1
            loss_reduction: token_mean
            normalize_reward: true
            ppo_loss_type: regular
            use_abs_kl: false
            use_kl_estimator_k3: true
            use_kl_in_reward: false
            use_kl_loss: true
            value_clip: 0.1
            value_head_prefix: value_head
        bf16: true
        ckpt_interval: 5
        ckpt_path: /root/ckpts/tau_bench/Qwen_Qwen2.5-3B-Instruct_v5-multi-domain
        critic:
            deepspeed_config:
                data_types:
                    grad_accum_dtype: fp32
                disable_trace_cache: false
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_optimizer:
                        device: none
                        pin_memory: true
                    offload_param:
                        device: none
                    reduce_bucket_size: auto
                    round_robin_gradients: true
                    stage: 3
                    stage3_max_live_parameters: auto
                    stage3_max_reuse_distance: auto
                    stage3_param_persistence_threshold: auto
                    stage3_prefetch_bucket_size: auto
                    sub_group_size: auto
                    zero_hpz_partition_size: 1
                    zero_quantized_gradients: false
                    zero_quantized_weights: false
            fsdp_config:
                cpu_offload: false
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: null
            optimizer_config:
                adam_betas:
                    - 0.9
                    - 0.999
                lr: 5e-06
                max_grad_norm: 1
                num_warmup_steps: 0
                offload_after_step: true
                weight_decay: 0.01
            sequence_parallel_size: 1
        critic_mini_batch_size: 64
        disable_fast_tokenizer: false
        dump_data_batch: false
        dump_eval_results: true
        epochs: 100
        eval_batch_size: 32
        eval_before_train: true
        eval_interval: 5
        export_path: /root/exports/tau_bench
        flash_attn: false
        gradient_checkpointing: true
        gradient_checkpointing_use_reentrant: false
        hf_save_interval: 20
        logger: wandb
        max_ckpts_to_keep: 3
        max_prompt_length: 16384
        micro_forward_batch_size_per_gpu: 1
        micro_train_batch_size_per_gpu: 1
        placement:
            colocate_all: true
            colocate_critic_reward: false
            colocate_policy_ref: true
            critic_num_gpus_per_node: 8
            critic_num_nodes: 1
            policy_num_gpus_per_node: 8
            policy_num_nodes: 1
            ref_num_gpus_per_node: 8
            ref_num_nodes: 1
            reward_num_gpus_per_node: 8
            reward_num_nodes: 1
        policy:
            deepspeed_config:
                data_types:
                    grad_accum_dtype: fp32
                disable_trace_cache: false
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_optimizer:
                        device: none
                        pin_memory: true
                    offload_param:
                        device: none
                    reduce_bucket_size: auto
                    round_robin_gradients: true
                    stage: 3
                    stage3_max_live_parameters: auto
                    stage3_max_reuse_distance: auto
                    stage3_param_persistence_threshold: auto
                    stage3_prefetch_bucket_size: auto
                    sub_group_size: auto
                    zero_hpz_partition_size: 1
                    zero_quantized_gradients: false
                    zero_quantized_weights: false
            fsdp_config:
                cpu_offload: false
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: Qwen/Qwen2.5-3B-Instruct
            optimizer_config:
                adam_betas:
                    - 0.9
                    - 0.999
                lr: 3e-07
                max_grad_norm: 0.5
                num_warmup_steps: 200
                offload_after_step: true
                weight_decay: 0.05
            record_memory: false
            sequence_parallel_size: 1
            use_torch_compile: false
        policy_mini_batch_size: 16
        project_name: tau_bench_rl
        ref:
            deepspeed_config:
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_param:
                        device: cpu
                        pin_memory: true
                    stage: 3
                    stage3_param_persistence_threshold: auto
            fsdp_config:
                cpu_offload: true
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: Qwen/Qwen2.5-3B-Instruct
            sequence_parallel_size: 1
        resume_mode: latest
        resume_path: null
        reward:
            deepspeed_config:
                gradient_clipping: 1
                prescale_gradient: false
                wall_clock_breakdown: false
                zero_optimization:
                    offload_param:
                        device: cpu
                        pin_memory: true
                    stage: 3
                    stage3_param_persistence_threshold: auto
            fsdp_config:
                cpu_offload: true
                fsdp_size: -1
                reshard_after_forward: true
            model:
                path: null
            sequence_parallel_size: 1
        run_name: tau_bench_qwen2_5_3b_20250807_064912
        seed: 42
        sequence_parallel_backend: ulysses
        strategy: fsdp2
        target_modules: all-linear
        train_batch_size: 64
        update_epochs_per_batch: 1
        update_ref_every_epoch: false
        use_orm_score: false
        use_sample_packing: false
