2025-08-06 18:30:03,834 INFO    MainThread:1871997 [wandb_setup.py:_flush():80] Current SDK version is 0.21.0
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_setup.py:_flush():80] Configure stats pid to 1871997
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_setup.py:_flush():80] Loading settings from /root/.config/wandb/settings
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_setup.py:_flush():80] Loading settings from /root/CTU-Agent-v0/training/wandb/settings
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_init.py:setup_run_log_directory():703] Logging user logs to /root/CTU-Agent-v0/training/wandb/run-20250806_183003-4uo67o11/logs/debug.log
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_init.py:setup_run_log_directory():704] Logging internal logs to /root/CTU-Agent-v0/training/wandb/run-20250806_183003-4uo67o11/logs/debug-internal.log
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_init.py:init():830] calling init triggers
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_init.py:init():835] wandb.init called with sweep_config: {}
config: {'data': {'train_data': ['data/tau_bench_multi/train.parquet'], 'val_data': ['data/tau_bench_multi/validation.parquet'], 'retail_val_data': ['data/tau_bench_retail/validation.parquet'], 'test_data': {'retail': 'data/tau_bench_test/retail_test.parquet', 'airline': 'data/tau_bench_test/airline_test.parquet'}}, 'trainer': {'placement': {'colocate_all': True, 'colocate_policy_ref': True, 'colocate_critic_reward': False, 'policy_num_nodes': 1, 'policy_num_gpus_per_node': 8, 'critic_num_nodes': 1, 'critic_num_gpus_per_node': 8, 'ref_num_nodes': 1, 'ref_num_gpus_per_node': 8, 'reward_num_nodes': 1, 'reward_num_gpus_per_node': 8}, 'sequence_parallel_backend': 'ulysses', 'strategy': 'fsdp2', 'policy': {'model': {'path': 'Qwen/Qwen2.5-3B-Instruct'}, 'deepspeed_config': {'zero_optimization': {'stage': 3, 'offload_param': {'device': 'none'}, 'offload_optimizer': {'device': 'none', 'pin_memory': True}, 'sub_group_size': 'auto', 'reduce_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_max_live_parameters': 'auto', 'stage3_max_reuse_distance': 'auto', 'round_robin_gradients': True, 'zero_hpz_partition_size': 1, 'zero_quantized_weights': False, 'zero_quantized_gradients': False}, 'disable_trace_cache': False, 'data_types': {'grad_accum_dtype': 'fp32'}, 'gradient_clipping': 1.0, 'wall_clock_breakdown': False, 'prescale_gradient': False}, 'optimizer_config': {'lr': 5e-07, 'adam_betas': [0.9, 0.999], 'weight_decay': 0.05, 'max_grad_norm': 0.5, 'offload_after_step': True, 'num_warmup_steps': 50}, 'fsdp_config': {'cpu_offload': False, 'reshard_after_forward': True, 'fsdp_size': -1}, 'sequence_parallel_size': 1, 'use_torch_compile': False, 'record_memory': False}, 'ref': {'model': {'path': 'Qwen/Qwen2.5-3B-Instruct'}, 'sequence_parallel_size': 1, 'deepspeed_config': {'zero_optimization': {'stage': 3, 'stage3_param_persistence_threshold': 'auto', 'offload_param': {'device': 'cpu', 'pin_memory': True}}, 'gradient_clipping': 1.0, 'prescale_gradient': False, 'wall_clock_breakdown': False}, 'fsdp_config': {'cpu_offload': True, 'reshard_after_forward': True, 'fsdp_size': -1}}, 'critic': {'model': {'path': None}, 'deepspeed_config': {'zero_optimization': {'stage': 3, 'offload_param': {'device': 'none'}, 'offload_optimizer': {'device': 'none', 'pin_memory': True}, 'sub_group_size': 'auto', 'reduce_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_max_live_parameters': 'auto', 'stage3_max_reuse_distance': 'auto', 'round_robin_gradients': True, 'zero_hpz_partition_size': 1, 'zero_quantized_weights': False, 'zero_quantized_gradients': False}, 'disable_trace_cache': False, 'data_types': {'grad_accum_dtype': 'fp32'}, 'gradient_clipping': 1.0, 'wall_clock_breakdown': False, 'prescale_gradient': False}, 'optimizer_config': {'lr': 5e-06, 'adam_betas': [0.9, 0.999], 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'offload_after_step': True, 'num_warmup_steps': 0}, 'fsdp_config': {'cpu_offload': False, 'reshard_after_forward': True, 'fsdp_size': -1}, 'sequence_parallel_size': 1}, 'reward': {'model': {'path': None}, 'deepspeed_config': {'zero_optimization': {'stage': 3, 'stage3_param_persistence_threshold': 'auto', 'offload_param': {'device': 'cpu', 'pin_memory': True}}, 'gradient_clipping': 1.0, 'prescale_gradient': False, 'wall_clock_breakdown': False}, 'fsdp_config': {'cpu_offload': True, 'reshard_after_forward': True, 'fsdp_size': -1}, 'sequence_parallel_size': 1}, 'algorithm': {'advantage_estimator': 'grpo', 'kl_target': None, 'init_kl_coef': 0.0, 'use_kl_estimator_k3': True, 'use_abs_kl': False, 'use_kl_in_reward': False, 'use_kl_loss': True, 'kl_loss_coef': 0.01, 'advantage_batch_normalize': False, 'value_head_prefix': 'value_head', 'ppo_loss_type': 'regular', 'loss_reduction': 'token_mean', 'lambd': 1.0, 'gamma': 1.0, 'eps_clip_low': 0.1, 'eps_clip_high': 0.1, 'clip_ratio_c': 3.0, 'value_clip': 0.1, 'normalize_reward': True}, 'gradient_checkpointing': True, 'gradient_checkpointing_use_reentrant': False, 'seed': 42, 'resume_mode': 'latest', 'resume_path': None, 'ckpt_path': '/root/ckpts/tau_bench/Qwen_Qwen2.5-3B-Instruct_v5-multi-domain', 'max_ckpts_to_keep': 3, 'ckpt_interval': 10, 'hf_save_interval': 20, 'export_path': '/root/exports/tau_bench', 'bf16': True, 'epochs': 50, 'update_epochs_per_batch': 1, 'train_batch_size': 64, 'policy_mini_batch_size': 16, 'critic_mini_batch_size': 64, 'micro_train_batch_size_per_gpu': 1, 'micro_forward_batch_size_per_gpu': 1, 'update_ref_every_epoch': False, 'use_sample_packing': True, 'eval_batch_size': 128, 'eval_before_train': True, 'eval_interval': 5, 'max_prompt_length': 16384, 'flash_attn': False, 'disable_fast_tokenizer': False, 'target_modules': 'all-linear', 'use_orm_score': False, 'project_name': 'tau_bench_rl', 'run_name': 'tau_bench_qwen2_5_3b_v1', 'logger': 'wandb', 'dump_data_batch': False, 'dump_eval_results': True}, 'generator': {'model_dtype': 'bfloat16', 'run_engines_locally': True, 'num_inference_engines': 2, 'backend': 'vllm', 'weight_sync_backend': 'nccl', 'inference_engine_tensor_parallel_size': 4, 'n_samples_per_prompt': 3, 'async_engine': True, 'batched': False, 'max_input_length': 16384, 'vllm_v1_disable_multiproc': True, 'enable_prefix_caching': True, 'enable_chunked_prefill': True, 'max_num_batched_tokens': 32768, 'enforce_eager': False, 'gpu_memory_utilization': 0.95, 'max_num_seqs': 256, 'remote_inference_engine_urls': ['127.0.0.1:8001'], 'max_turns': 20, 'override_existing_update_group': 'disable', 'sampling_params': {'max_generate_length': 1024, 'temperature': 0.8, 'top_p': 0.95, 'min_p': 0.0, 'top_k': -1}, 'use_conversation_multi_turn': True, 'use_native_tool_calling': True, 'eval_sampling_params': {'max_generate_length': 1024, 'temperature': 0.0, 'top_p': 1.0, 'min_p': 0.0, 'top_k': -1}, 'eval_n_samples_per_prompt': 1, 'zero_reward_on_non_stop': True}, 'environment': {'env_class': 'tau_bench', 'skyrl_gym': {'max_env_workers': 16, 'tau_bench': {'user_strategy': 'llm', 'user_model': 'gpt-4o', 'user_provider': 'openai', 'max_turns': 20, 'use_native_tool_calling': True, 'timeout': 120, 'log_conversations': True, 'log_tool_calls': True, 'cache_environments': True, 'parallel_user_sim': False}}}, 'deepspeed_config': {'train': {'zero_optimization': {'stage': 3, 'offload_param': {'device': 'none'}, 'offload_optimizer': {'device': 'none', 'pin_memory': True}, 'sub_group_size': 'auto', 'reduce_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_max_live_parameters': 'auto', 'stage3_max_reuse_distance': 'auto', 'round_robin_gradients': True, 'zero_hpz_partition_size': 1, 'zero_quantized_weights': False, 'zero_quantized_gradients': False}, 'disable_trace_cache': False, 'data_types': {'grad_accum_dtype': 'fp32'}, 'gradient_clipping': 1.0, 'wall_clock_breakdown': False, 'prescale_gradient': False}, 'eval': {'zero_optimization': {'stage': 3, 'stage3_param_persistence_threshold': 'auto', 'offload_param': {'device': 'cpu', 'pin_memory': True}}, 'gradient_clipping': 1.0, 'prescale_gradient': False, 'wall_clock_breakdown': False}}, '_wandb': {}}
2025-08-06 18:30:03,835 INFO    MainThread:1871997 [wandb_init.py:init():871] starting backend
2025-08-06 18:30:04,042 INFO    MainThread:1871997 [wandb_init.py:init():874] sending inform_init request
2025-08-06 18:30:04,048 INFO    MainThread:1871997 [wandb_init.py:init():882] backend started and connected
2025-08-06 18:30:04,051 INFO    MainThread:1871997 [wandb_init.py:init():953] updated telemetry
2025-08-06 18:30:04,058 INFO    MainThread:1871997 [wandb_init.py:init():977] communicating run to backend with 90.0 second timeout
2025-08-06 18:30:04,480 INFO    MainThread:1871997 [wandb_init.py:init():1029] starting run threads in backend
2025-08-06 18:30:04,644 INFO    MainThread:1871997 [wandb_run.py:_console_start():2458] atexit reg
2025-08-06 18:30:04,644 INFO    MainThread:1871997 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-08-06 18:30:04,644 INFO    MainThread:1871997 [wandb_run.py:_redirect():2375] Wrapping output streams.
2025-08-06 18:30:04,644 INFO    MainThread:1871997 [wandb_run.py:_redirect():2398] Redirects installed.
2025-08-06 18:30:04,646 INFO    MainThread:1871997 [wandb_init.py:init():1075] run started, returning control to user process
2025-08-06 18:32:05,225 INFO    MainThread:1871997 [wandb_run.py:_finish():2224] finishing run mert_cemri-eecs/tau_bench_rl/4uo67o11
2025-08-06 18:32:05,226 INFO    MainThread:1871997 [wandb_run.py:_atexit_cleanup():2423] got exitcode: 0
2025-08-06 18:32:05,227 ERROR   Dummy-19  :1871997 [redirect.py:_on_write():664] [all runs] error in stderr callback
Traceback (most recent call last):
  File "/root/miniconda3/envs/ctu/lib/python3.12/site-packages/wandb/sdk/lib/redirect.py", line 662, in _on_write
    cb(written_data)
  File "/root/miniconda3/envs/ctu/lib/python3.12/site-packages/wandb/sdk/wandb_run.py", line 2385, in <lambda>
    lambda data: self._console_raw_callback("stderr", data),
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/ctu/lib/python3.12/site-packages/wandb/sdk/wandb_run.py", line 398, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/ctu/lib/python3.12/site-packages/wandb/sdk/wandb_run.py", line 464, in wrapper_fn
    raise UsageError(message)
wandb.errors.errors.UsageError: Run (4uo67o11) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.
2025-08-06 18:32:05,227 INFO    MainThread:1871997 [wandb_run.py:_restore():2405] restore
2025-08-06 18:32:05,229 INFO    MainThread:1871997 [wandb_run.py:_restore():2411] restore done
2025-08-06 18:32:05,605 INFO    MainThread:1871997 [wandb_run.py:_footer_history_summary_info():3903] rendering history
2025-08-06 18:32:05,606 INFO    MainThread:1871997 [wandb_run.py:_footer_history_summary_info():3935] rendering summary
2025-08-06 18:32:05,606 INFO    MainThread:1871997 [wandb_run.py:_footer_sync_info():3864] logging synced files
