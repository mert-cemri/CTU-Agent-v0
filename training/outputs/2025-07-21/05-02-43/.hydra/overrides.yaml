- data.train_data=['data/tau_bench_retail/train.parquet']
- data.val_data=['data/tau_bench_retail/validation.parquet']
- trainer.policy.model.path=Qwen/Qwen2.5-1.5B-Instruct
- trainer.ref.model.path=Qwen/Qwen2.5-1.5B-Instruct
- trainer.placement.policy_num_gpus_per_node=8
- trainer.placement.ref_num_gpus_per_node=8
- trainer.placement.critic_num_gpus_per_node=8
- trainer.placement.reward_num_gpus_per_node=8
- generator.num_inference_engines=2
- generator.inference_engine_tensor_parallel_size=4
- trainer.ckpt_path=/root/ckpts/tau_bench
- trainer.export_path=/root/exports/tau_bench
- trainer.epochs=5
- trainer.train_batch_size=256
- trainer.policy_mini_batch_size=64
- trainer.micro_train_batch_size_per_gpu=1
- trainer.micro_forward_batch_size_per_gpu=2
- trainer.max_prompt_length=16384
- trainer.eval_batch_size=128
- trainer.eval_before_train=true
- trainer.eval_interval=5
- trainer.policy.optimizer_config.lr=1.0e-6
- trainer.algorithm.use_kl_loss=true
- trainer.algorithm.kl_loss_coef=0.001
- trainer.ckpt_interval=10
- trainer.hf_save_interval=20
- generator.max_turns=20
- generator.use_conversation_multi_turn=true
- generator.batched=false
- generator.async_engine=true
- generator.n_samples_per_prompt=3
- generator.gpu_memory_utilization=0.7
- generator.max_input_length=16384
- generator.sampling_params.max_generate_length=1024
- generator.sampling_params.temperature=0.7
- generator.sampling_params.top_p=0.9
- generator.override_existing_update_group=force_new
- environment.env_class=tau_bench
- environment.skyrl_gym.tau_bench.user_strategy=llm
- environment.skyrl_gym.tau_bench.user_model=gpt-4o
- environment.skyrl_gym.tau_bench.user_provider=openai
- environment.skyrl_gym.tau_bench.max_turns=6
- environment.skyrl_gym.max_env_workers=16
- trainer.logger=wandb
- trainer.project_name=tau_bench_rl
- trainer.run_name=tau_bench_qwen1_5b_20250721_050234
- trainer.resume_mode=latest
